{"cells":[{"cell_type":"code","source":["secret_scope = \"scope\"                                         # your secret scope\nproject = \"key\"                                                # the key in your secret scope that hold the CDF api-key you want to use\nsource_system = \"orca\"                                         # an identifier for the source system of the data\nfile_name = \"Assets_v0.768\"                                    # name for your file, we use this is name of the table in raw\nfile_location = \"/FileStore/tables/wherever_it_is.xls\"         # location of your file in dbfs\nsheetName = \"Sheet1\"                                           # Excel \"Sheet Name\"\nkey_column = \"id\"                                              # name of the column in the sheet that we can use as unique identifier"],"metadata":{},"outputs":[],"execution_count":1},{"cell_type":"code","source":["new_table = spark.read.format(\"com.crealytics.spark.excel\") \\\n    .option(\"location\", file_location) \\\n    .option(\"useHeader\", \"true\") \\\n    .option(\"treatEmptyValuesAsNulls\", \"true\") \\\n    .option(\"inferSchema\", \"true\") \\\n    .option(\"addColorColumns\", \"False\") \\\n    .option(\"sheetName\", sheetName) \\\n    .load()\nnew_table.createOrReplaceTempView(\"new_table\")"],"metadata":{},"outputs":[],"execution_count":2},{"cell_type":"code","source":["# if base setup is already there\nfrom cognite.client import CogniteClient\n\nclient = CogniteClient(api_key=dbutils.secrets.get(secret_scope, project))\ndb = source_system + \"_dump\"\ntable = file_name\nclient.raw.create_tables(database_name=db, table_names=[table])"],"metadata":{},"outputs":[],"execution_count":3},{"cell_type":"code","source":["# if raw needs to be set up\nfrom cognite.client import CogniteClient\n\nclient = CogniteClient(api_key=dbutils.secrets.get(secret_scope, project))\ndb = \"raw\"\ntable = file_name\nclient.raw.create_databases([db])\nclient.raw.create_tables(database_name=db, table_names=[table])\n\ndb = \"staging\"\ntable = \"asset_hierarchy\"\nclient.raw.create_databases([db])\nclient.raw.create_tables(database_name=db, table_names=[table])"],"metadata":{},"outputs":[],"execution_count":4},{"cell_type":"code","source":["from pyspark.sql.functions import *\nnew_table = new_table.withColumn(\"key\",col(key_column))"],"metadata":{},"outputs":[],"execution_count":5},{"cell_type":"code","source":["new_table_raw= spark.read.format(\"com.cognite.spark.datasource\") \\\n    .option(\"type\", \"raw\") \\\n    .option(\"database\", \"raw\") \\\n    .option(\"table\", file_name) \\\n    .option(\"apiKey\", dbutils.secrets.get(secret_scope, project)) \\\n    .schema(new_table.schema) \\\n    .load()\nnew_table_raw.createOrReplaceTempView(\"new_table_raw\")"],"metadata":{},"outputs":[],"execution_count":6},{"cell_type":"code","source":["new_table.write.insertInto(\"new_table_raw\")"],"metadata":{},"outputs":[],"execution_count":7},{"cell_type":"code","source":["display(new_table_raw)"],"metadata":{},"outputs":[],"execution_count":8}],"metadata":{"name":"Upload Excel file to RAW layer","notebookId":3473348351830934},"nbformat":4,"nbformat_minor":0}